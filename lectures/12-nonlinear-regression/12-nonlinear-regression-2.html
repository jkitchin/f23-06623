

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Uncertainty estimates from curvefit and scipy.optimize.minimize &#8212; f23-06623</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lectures/12-nonlinear-regression/12-nonlinear-regression-2';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Constrained minimization" href="../13-constrained-optimization/13-constrained-optimization.html" />
    <link rel="prev" title="Introduction to nonlinear regression" href="../11-regression/11-regression.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../syllabus.html">
  
  
  
  
    
    
      
    
    
    <img src="../../_static/06623-roadmap.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../_static/06623-roadmap.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../syllabus.html">
                    Syllabus for  06-623 Mathematical Modeling of Chemical Engineering Processes
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Lectures</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../toc.html">Fall 2023 - 06-623 Mathematical modeling of chemical engineering processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00-intro/00-intro.html">Introduction to 06-623 and Jupyter Lab</a></li>



<li class="toctree-l1"><a class="reference internal" href="../01-jupyter/01-jupyter.html">Jupyter Lab</a></li>







<li class="toctree-l1"><a class="reference internal" href="../02-integration-1/02-integration-1.html">Integration in Python</a></li>



<li class="toctree-l1"><a class="reference internal" href="../03-fode-1/03-fode-1.html">Solutions to first-order differential equations by integration</a></li>



<li class="toctree-l1"><a class="reference internal" href="../04-fode-2/04-fode-2.html">Families of solutions to FODEs</a></li>

<li class="toctree-l1"><a class="reference internal" href="../05-nth-odes/05-nth-odes.html">Higher order differential equations</a></li>

<li class="toctree-l1"><a class="reference internal" href="../07-nla-1/07-nla-1.html">Introduction to nonlinear algebra</a></li>

<li class="toctree-l1"><a class="reference internal" href="../08-nla-2/08-nla-2.html">Advanced topics in nonlinear algebra</a></li>




<li class="toctree-l1"><a class="reference internal" href="../09-bvp/09-bvp.html">Boundary Value Problems in differential equations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../10-min-max/10-min-max.html">Introduction to optimization</a></li>



<li class="toctree-l1"><a class="reference internal" href="../11-regression/11-regression.html">Introduction to nonlinear regression</a></li>



<li class="toctree-l1 current active"><a class="current reference internal" href="#">Uncertainty estimates from curvefit and scipy.optimize.minimize</a></li>



<li class="toctree-l1"><a class="reference internal" href="../13-constrained-optimization/13-constrained-optimization.html">Constrained minimization</a></li>


<li class="toctree-l1"><a class="reference internal" href="../15-intro-linear-algebra/15-intro-linear-algebra.html">Introduction to Linear algebra</a></li>





<li class="toctree-l1"><a class="reference internal" href="../16-linear-algebra/16-linear-algebra.html">Linear algebraic equations</a></li>




<li class="toctree-l1"><a class="reference internal" href="../17-linear-algebra-2/17-linear-algebra-2.html">Advanced topics in linear algebra</a></li>





<li class="toctree-l1"><a class="reference internal" href="../18-linear-regression/18-linear-regression.html">Linear regression</a></li>



<li class="toctree-l1"><a class="reference internal" href="../19-introduction-to-autograd/19-introduction-to-jax.html">Introduction to automatic differentiation with jax</a></li>




<li class="toctree-l1"><a class="reference internal" href="../20-autograd-applications/20-jax-applications.html">Applications of automatic differentiation</a></li>



<li class="toctree-l1"><a class="reference internal" href="../21-machine-learning/21-machine-learning-jax.html">Introduction to machine learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../22-ml-2/22-ml-2-jax.html">Advanced topics in ML</a></li>
<li class="toctree-l1"><a class="reference internal" href="../23-gp/23-gp.html">Gaussian process regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Index</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">About the book</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../execution-statistics.html">Build statistics</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://jupyterhub-dev.cheme.cmu.edu/hub/user-redirect/git-pull?repo=https%3A//github.com/jkitchin/f23-06623&urlpath=lab/tree/f23-06623/f23-06623/lectures/12-nonlinear-regression/12-nonlinear-regression-2.ipynb&branch=main" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onJupyterHub"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_jupyterhub.svg">
  </span>
<span class="btn__text-container">JupyterHub</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/jkitchin/f23-06623/blob/main/f23-06623/lectures/12-nonlinear-regression/12-nonlinear-regression-2.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/jkitchin/f23-06623" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/jkitchin/f23-06623/issues/new?title=Issue%20on%20page%20%2Flectures/12-nonlinear-regression/12-nonlinear-regression-2.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/lectures/12-nonlinear-regression/12-nonlinear-regression-2.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Uncertainty estimates from curvefit and scipy.optimize.minimize</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Uncertainty estimates from curvefit and scipy.optimize.minimize</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#effects-of-outliers-on-regression">Effects of outliers on regression</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#minimizing-the-summed-absolute-errors">Minimizing the summed absolute errors</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#robust-regression-approaches">Robust regression approaches</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#least-median-regression">Least Median regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#weighted-nonlinear-regression">Weighted nonlinear regression</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <p><img alt="out-liar" src="https://i2.wp.com/oklahomaanalytics.com/wp-content/uploads/2016/12/outlier-pic-1.jpg?w=589" /></p>
<section id="uncertainty-estimates-from-curvefit-and-scipy-optimize-minimize">
<h1>Uncertainty estimates from curvefit and scipy.optimize.minimize<a class="headerlink" href="#uncertainty-estimates-from-curvefit-and-scipy-optimize-minimize" title="Permalink to this heading">#</a></h1>
<p>We previously examined how to estimate uncertainty from the covariance matrix returned from curve_fit. Recall we need the diagonal of the covariance matrix, which is estimated during the fitting.  The covariance matrix is related to the inverse Hessian matrix. We will explore how these are related here.</p>
<p>We will consider fitting a line to the following data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">curve_fit</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">7.5</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.14</span><span class="p">,</span> <span class="mf">1.91</span><span class="p">,</span> <span class="mf">2.48</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">m</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span>


<span class="n">p</span><span class="p">,</span> <span class="n">pcov</span> <span class="o">=</span> <span class="n">curve_fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="n">ftol</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span> <span class="n">xtol</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span> <span class="n">gtol</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">pcov</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.2404     1.14399999]
[[ 0.004 -0.022]
 [-0.022  0.162]]
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">scipy.optimize.minimize</span></code> does not return the covariance matrix; with <em>some</em> of the methods, it returns an estimate of the inverse Hessian matrix. In theory, the covariance matrix and the inverse hessian are related to each other with $cov = 0.5 * H^{-1}$. Note this relationship is specific to the minimization of the summed squared errors.</p>
<p>Here we solve this problem again with minimize.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>


<span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">pars</span><span class="p">,</span> <span class="n">_x</span><span class="p">):</span>
    <span class="n">_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">_x</span><span class="p">)</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">pars</span>
    <span class="k">return</span> <span class="n">m</span> <span class="o">*</span> <span class="n">_x</span> <span class="o">+</span> <span class="n">b</span>


<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">pars</span><span class="p">):</span>
    <span class="n">errs</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">model</span><span class="p">(</span><span class="n">pars</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">errs</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>


<span class="n">sol</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sol</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>

<span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">sol</span><span class="o">.</span><span class="n">hess_inv</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.2404     1.14399997]
[[ 0.01  -0.066]
 [-0.066  0.491]]
</pre></div>
</div>
</div>
</div>
<p>That doesn’t look very good. <strong>But</strong>, remember that it is an <em>estimate</em> of the Hessian and we need to be careful about the accuracy. The minimizer terminates when the solution reaches the tolerance, <em>not</em> when the inverse Hessian is accurate! If we make the tolerance smaller, we get a more accurate result.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">?</span>minimize
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sol</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sol</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
<span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">sol</span><span class="o">.</span><span class="n">hess_inv</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.24039999 1.144     ]
[[ 0.004 -0.022]
 [-0.022  0.167]]
</pre></div>
</div>
</div>
</div>
<p>With the increased accuracy, you can see the covariance is approximately equal to 1/2 the inverse Hessian. That means you can use it to estimate the uncertainty in the same way we did with curve_fit.</p>
<p>Not all solvers generate the inverse Hessian matrix, e.g. <code class="docutils literal notranslate"><span class="pre">SLSQP</span></code> does not do it. You have three options. One is always to compute the Hessian analytically. The other two options rely on libraries that use automatic differentiation to compute the relevant derivatives. One is to use numdifftools (which you may have to install). Either way, you have to compute the Hessian on the objective function that is being minimized. One way to get this is to use a numerical package designed to compute this. We can use <a class="reference external" href="https://numdifftools.readthedocs.io/en/latest/">numdifftools</a> for this.</p>
<p>Now, similar to what we did with <code class="docutils literal notranslate"><span class="pre">scipy.misc.derivative</span></code>, we can write a function and then use numdifftools to get the Hessian of the function. Here, we define the sum of the squared errors function, then create a Hessian function for that. We can use the Hessian function to evaluate the Hessian at the parameters at the minimum. We use <code class="docutils literal notranslate"><span class="pre">numpy.linalg.inv</span></code> to get the inverse of the Hessian to compute the covariance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numdifftools</span> <span class="k">as</span> <span class="nn">nd</span>


<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">pars</span><span class="p">):</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">pars</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="p">(</span><span class="n">m</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>


<span class="n">H</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">Hessian</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>  <span class="c1"># H is an executable function now that takes one argument, the pars.</span>
<span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">H</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>  <span class="c1"># This is how you get the inverse of the Hessian</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[ 0.004, -0.02 ],
       [-0.02 ,  0.15 ]])
</pre></div>
</div>
</div>
</div>
<p>Let’s work out the analytical solution.</p>
<p>$SSE = \sum (y - (m x + b))^2$</p>
<p>$\frac{\partial SSE}{\partial m} = \sum 2 (y - (m x + b)) * (-x)$</p>
<p>$\frac{\partial SSE}{\partial b} = \sum 2 (y - (m x + b)) * (-1)$</p>
<p>NExt you need the four second derivatives (the off diagonals are the same because it does not matter which order you differentiate in).</p>
<p>$\frac{\partial^2 SSE}{\partial m^2} = \sum 2 x^2$</p>
<p>$\frac{\partial^2 SSE}{\partial m b} = \sum 2 x$</p>
<p>$\frac{\partial^2 SSE}{\partial b^2} = \sum 2 $</p>
<p>The last one is a little tricky to implement, we need a sum of the value 2 for each data point, so we have to create an array of 2s to add up.</p>
<p>You can see here that the analytical solution is equivalent to the one from <code class="docutils literal notranslate"><span class="pre">numdifftools</span></code> (and also, that it does not depend on the values of $m,b$! That is actually a feature of this model being linear.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">aH</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">x</span><span class="p">)],</span>
               <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">))]])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">aH</span><span class="p">)</span>

<span class="n">H</span><span class="p">(</span><span class="n">sol</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[375.  50.]
 [ 50.  10.]]
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[375.,  50.],
       [ 50.,  10.]])
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">numdifftools</span></code> (<a class="reference external" href="https://pypi.org/project/numdifftools/">https://pypi.org/project/numdifftools/</a>) is a numerical differentiation package. It is more sophisticated than <code class="docutils literal notranslate"><span class="pre">scipy.misc.derivative</span></code> but is fundamentally still a numerical approximation to the derivatives. Now you can use these to estimate the uncertainties even for optimizers that don’t provide the estimated inverse Hessian.</p>
<p>Later we will learn about one more approach to getting the derivatives that is used in machine learning called automatic differentiation.</p>
</section>
<section id="effects-of-outliers-on-regression">
<h1>Effects of outliers on regression<a class="headerlink" href="#effects-of-outliers-on-regression" title="Permalink to this heading">#</a></h1>
<p>Outliers can have a significant effect on the fit of a model to data. Let’s consider this example, where we want to fit a line to some data that has an outlier in it. This is just a linear regression, and we start out using <code class="docutils literal notranslate"><span class="pre">numpy.polyfit</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">7.5</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.14</span><span class="p">,</span> <span class="mf">1.91</span><span class="p">,</span> <span class="mf">2.48</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]</span>
<span class="c1">#                            ^</span>
<span class="c1">#                            |</span>
<span class="c1">#                         outlier</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<span class="n">xfit</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;bo&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xfit</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">polyval</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">xfit</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.2404 1.144 ]
</pre></div>
</div>
<img alt="../../_images/3f0fd3843cf57259726871dcebbc60b01194e2c82902ad201ad04ede3c1f420e.png" src="../../_images/3f0fd3843cf57259726871dcebbc60b01194e2c82902ad201ad04ede3c1f420e.png" />
</div>
</div>
<p>You can see that the fitted line is “dragged” towards the outlier. We say that least squares minimization is not <em>robust</em> to outliers.</p>
<p>This may be undesirable because if you believe there is an outlier, perhaps due to experimental error, then this point affects the accuracy of the model more than the other points you believe to be more accurate.</p>
<p>Today we will consider a variety of approaches to minimize the effects of outliers. We first begin by re-examining how these parameters are obtained. Here, we illustrate that the results from polyfit are equivalent to minimizing the summed squared errors between the model and the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>


<span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">pars</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># this just makes sure that x is an array</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">pars</span>
    <span class="k">return</span> <span class="n">m</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span>


<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">pars</span><span class="p">):</span>
    <span class="n">errs</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">model</span><span class="p">(</span><span class="n">pars</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">errs</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>


<span class="n">sol</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;ro&quot;</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">model</span><span class="p">(</span><span class="n">sol</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">X</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/f3474bc635cb114e1b6eb8e58b2804eb01e79887c5f615c07908abc31cb25050.png" src="../../_images/f3474bc635cb114e1b6eb8e58b2804eb01e79887c5f615c07908abc31cb25050.png" />
</div>
</div>
<p>The problem is that we are minimizing the error<sup>2</sup>, which puts more weight on large errors than small errors.</p>
<p>Least squares regression is also called L<sub>2</sub> norm regression, that is we minimize the L<sub>2</sub> norm of the error vector.</p>
<p>Sum of error squared = dot(err, err) = err &#64; err</p>
</section>
<section id="minimizing-the-summed-absolute-errors">
<h1>Minimizing the summed absolute errors<a class="headerlink" href="#minimizing-the-summed-absolute-errors" title="Permalink to this heading">#</a></h1>
<p>We can choose to minimize another objective function, for example the summed absolute value of the errors. This will reduce the emphasis on large errors. This is  also called L<sub>1</sub> norm regression.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">pars</span><span class="p">):</span>
    <span class="n">errs</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">model</span><span class="p">(</span><span class="n">pars</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">errs</span><span class="p">))</span>


<span class="n">L1_sol</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">L1_sol</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;bo&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xfit</span><span class="p">,</span> <span class="n">model</span><span class="p">(</span><span class="n">L1_sol</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">xfit</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">objective</span><span class="p">(</span><span class="n">L1_sol</span><span class="o">.</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.26845682 1.14      ]
1.230000002431845
</pre></div>
</div>
<img alt="../../_images/74b0c19ce014a69c1e7418c407869ccc898d3cf1b902c878a18a0506cf750776.png" src="../../_images/74b0c19ce014a69c1e7418c407869ccc898d3cf1b902c878a18a0506cf750776.png" />
</div>
</div>
<p>There is a historical reason this is not done a lot, and that is the absolute value function has a discontinuity in its first derivative at the origin which can be problematic in some optimization algorithms. It is obviously not a problem here, and you can see that the outlier has less of an effect on the fitted line in this case.</p>
<p>Finally, we can generalize these ideas to something called L<sub>p</sub> norm regressions where we seek to minimize:</p>
<p>$\sum |\epsilon_i|^p$</p>
<p>In <a class="reference external" href="https://www.tandfonline.com/doi/abs/10.1080/00401706.1972.10488892">this paper</a> a value of $p=1.5$ is recommended for general use. Note this is less than two, and greater than one, so it is expected to have an intermediate effect compared to L<sub>1</sub> and L<sub>2</sub> norm regression.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">pars</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="mf">1.5</span>
    <span class="n">errs</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">model</span><span class="p">(</span><span class="n">pars</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">errs</span><span class="p">)</span> <span class="o">**</span> <span class="n">p</span><span class="p">)</span>


<span class="n">Lp_sol</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">Lp_sol</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;bo&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xfit</span><span class="p">,</span> <span class="n">model</span><span class="p">(</span><span class="n">Lp_sol</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">xfit</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.25741034 1.15352086]
</pre></div>
</div>
<img alt="../../_images/a6fb764afe18141c03efb2be5f62afbd8c2e21af8a20170998d56a937addf078.png" src="../../_images/a6fb764afe18141c03efb2be5f62afbd8c2e21af8a20170998d56a937addf078.png" />
</div>
</div>
<p>The downside of these approaches is that they complicate the analysis of uncertainty. The uncertainty analysis we have considered so far is only formally correct when we minimize the summed squared errors. It is only approximately correct when something else is minimized.</p>
<section id="robust-regression-approaches">
<h2>Robust regression approaches<a class="headerlink" href="#robust-regression-approaches" title="Permalink to this heading">#</a></h2>
<p>An alternative approach to least squares or absolute error minimization is called robust regression (see Applied Regression Analysis, 3rd edition, Draper and Smith, chapter 25). This is a class of methods that uses a different metric to minimize in the objective function.</p>
<p>The simplest approach is to minimize the median of the squared error. Note that minimizing the sum of squared errors is practically like minimizing the average or mean squared error. If you have a symmetric distribution of errors, then the mean and median are practically the same. If there is an outlier, however, the mean will be skewed towards the outlier, while the median will be at a position that splits the distribution in half, and is closer to what you believe the mean to be.</p>
<p>Here we show that given an asymmetric distribution, the median is smaller than the mean.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">errs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">errs</span><span class="o">**</span><span class="mi">2</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">s</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">s</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;median&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">);</span> <span class="c1"># this gets rid of the x-label</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/2744bed968a9e500e378a1f232e8666e07c3d0600ff058396016c8c017fe45eb.png" src="../../_images/2744bed968a9e500e378a1f232e8666e07c3d0600ff058396016c8c017fe45eb.png" />
</div>
</div>
</section>
<section id="least-median-regression">
<h2>Least Median regression<a class="headerlink" href="#least-median-regression" title="Permalink to this heading">#</a></h2>
<p>It is straightforward to modify the objective function to minimize the median of the squared errors.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">pars</span><span class="p">):</span>
    <span class="n">errs</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">model</span><span class="p">(</span><span class="n">pars</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">errs</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>


<span class="n">LMS_sol</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">LMS_sol</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;bo&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xfit</span><span class="p">,</span> <span class="n">model</span><span class="p">(</span><span class="n">LMS_sol</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">xfit</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.28599999 1.16750001]
</pre></div>
</div>
<img alt="../../_images/71830343e836878f3d3af2d23a42fa720e5461812cf3b3acc3f9fe96257dd499.png" src="../../_images/71830343e836878f3d3af2d23a42fa720e5461812cf3b3acc3f9fe96257dd499.png" />
</div>
</div>
</section>
<section id="weighted-nonlinear-regression">
<h2>Weighted nonlinear regression<a class="headerlink" href="#weighted-nonlinear-regression" title="Permalink to this heading">#</a></h2>
<p>Outliers often are associated with larger uncertainties about their values. An alternative approach to the methods described above is to use weights to say how important each data point is. This example is adapted from <a class="reference external" href="https://www.mathworks.com/help/stats/examples/weighted-nonlinear-regression.html">https://www.mathworks.com/help/stats/examples/weighted-nonlinear-regression.html</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">109</span><span class="p">,</span> <span class="mi">149</span><span class="p">,</span> <span class="mi">149</span><span class="p">,</span> <span class="mi">191</span><span class="p">,</span> <span class="mi">213</span><span class="p">,</span> <span class="mi">224</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;bo&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Incubation (days)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;BOD&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/1e3839fbe90aae20316f499856fec8ee0ec3e96a0def8fd54e1a897ca78d18cf.png" src="../../_images/1e3839fbe90aae20316f499856fec8ee0ec3e96a0def8fd54e1a897ca78d18cf.png" />
</div>
</div>
<p>The aim of this work is to fit a nonlinear model $y= a (1 - e^{-b x})$ to this data. We first consider a standard minimization of the sum squared errors. Inspection of the model suggests at large x, $a$ is a plateau value, which we can read from the graph. For the value of $b$, we might estimate a half-life at about one day and solve $110 = 240(1 - e^{-b})$</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="mi">110</span> <span class="o">/</span> <span class="mi">240</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.6131044728864087
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;bo&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="mi">220</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">0.6</span> <span class="o">*</span> <span class="n">x</span><span class="p">)));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/7329215aa6d5f8a43f5f3e541f0c20cfffc2d4e7f53db505d805aa3202fb3735.png" src="../../_images/7329215aa6d5f8a43f5f3e541f0c20cfffc2d4e7f53db505d805aa3202fb3735.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">pars</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">pars</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">b</span> <span class="o">*</span> <span class="n">x</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">pars</span><span class="p">):</span>
    <span class="n">errs</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">model</span><span class="p">(</span><span class="n">pars</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">errs</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>


<span class="n">guesses</span> <span class="o">=</span> <span class="p">[</span><span class="mi">240</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]</span>

<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>

<span class="n">sol</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">guesses</span><span class="p">)</span>
<span class="n">pars</span> <span class="o">=</span> <span class="n">sol</span><span class="o">.</span><span class="n">x</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;bo&quot;</span><span class="p">)</span>
<span class="n">xfit</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xfit</span><span class="p">,</span> <span class="n">model</span><span class="p">(</span><span class="n">pars</span><span class="p">,</span> <span class="n">xfit</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Incubation (days)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;BOD&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/88c273382f37a235e6e5d2b102af9af964531bda3041d2a1cc42b40a7be1ecfe.png" src="../../_images/88c273382f37a235e6e5d2b102af9af964531bda3041d2a1cc42b40a7be1ecfe.png" />
</div>
</div>
<p>The fit generally goes through the data, but it is not clear if there is a small outlier near 2 that is skewing the fit, and perhaps leading to an inaccurate asymptote at long times.</p>
<p>Suppose, however, that these data points represent averages from multiple measurements, and we only measured the first two points once, and the rest of the points 5 times. In this case, we might want to put more <em>weight</em> on the points we measured multiple times.</p>
<p>We achieve this by modifying the objective function, in this case multiplying each error by the number of times the measurement was made. This makes reducing errors on points we measured a lot more important than the points we measured less.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">pars</span><span class="p">):</span>
    <span class="n">errs</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">model</span><span class="p">(</span><span class="n">pars</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span> <span class="o">*</span> <span class="n">w</span>  <span class="c1"># multiply the errors by the weights</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">errs</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>


<span class="n">guesses</span> <span class="o">=</span> <span class="p">[</span><span class="mi">240</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span>

<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>

<span class="n">sol</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">guesses</span><span class="p">)</span>
<span class="n">pars</span> <span class="o">=</span> <span class="n">sol</span><span class="o">.</span><span class="n">x</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pars</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;bo&quot;</span><span class="p">)</span>
<span class="n">xfit</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xfit</span><span class="p">,</span> <span class="n">model</span><span class="p">(</span><span class="n">pars</span><span class="p">,</span> <span class="n">xfit</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Incubation (days)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;BOD&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[230.77020764   0.35563066]
</pre></div>
</div>
<img alt="../../_images/fcaf892fc6ee3203de024d9ec9e56d59fd18e5710660bfc9c7696de3b58f9d55.png" src="../../_images/fcaf892fc6ee3203de024d9ec9e56d59fd18e5710660bfc9c7696de3b58f9d55.png" />
</div>
</div>
<p>The result here is that the model fits the points we measured a lot better than the points we measured once.</p>
<p>There are many ways you could choose to weight the points depending on what you know about them. If you have uncertainties about the measured data, you can weight the points accordingly, e.g. defining the weights as inversely proportional to the uncertainty.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">se</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="p">)</span>  <span class="c1"># these are uncertainties/std err on each measurement</span>
<span class="n">w</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">se</span>  <span class="c1"># weight is inversely proportional to the SE.</span>


<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">pars</span><span class="p">):</span>
    <span class="n">errs</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">model</span><span class="p">(</span><span class="n">pars</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span> <span class="o">*</span> <span class="n">w</span>  <span class="c1"># multiply the errors by the weights</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">errs</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>


<span class="n">guesses</span> <span class="o">=</span> <span class="p">[</span><span class="mi">240</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span>

<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>

<span class="n">sol</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">guesses</span><span class="p">)</span>
<span class="n">pars</span> <span class="o">=</span> <span class="n">sol</span><span class="o">.</span><span class="n">x</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pars</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;bo&quot;</span><span class="p">)</span>
<span class="n">xfit</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xfit</span><span class="p">,</span> <span class="n">model</span><span class="p">(</span><span class="n">pars</span><span class="p">,</span> <span class="n">xfit</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Incubation (days)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;BOD&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[230.12681081   0.36025669]
</pre></div>
</div>
<img alt="../../_images/be7631a91a2548a008c70345453e435ba970a9831ee82fa842b0d1635a5c4b0f.png" src="../../_images/be7631a91a2548a008c70345453e435ba970a9831ee82fa842b0d1635a5c4b0f.png" />
</div>
</div>
<p>you can see the errors like this.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">errs</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">model</span><span class="p">(</span><span class="n">pars</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">errs</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([39.38600932, 30.83044152, -3.036934  , -1.1358961 ,  1.35586146,
        0.14499036])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># find time to reach 90% of saturation</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">root</span>


<span class="k">def</span> <span class="nf">g</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">(</span><span class="n">pars</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.9</span> <span class="o">*</span> <span class="mi">230</span>


<span class="n">root</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> message: The solution converged.
 success: True
  status: 1
     fun: [-1.421e-12]
       x: [ 6.378e+00]
    nfev: 8
    fjac: [[-1.000e+00]]
       r: [-8.332e+00]
     qtf: [ 1.997e-07]
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this heading">#</a></h1>
<p>Regression is an important technical skill required in modern engineering. It is the method which we use to convert data into models. Sometimes it is the parameters that are important, e.g. when they represent properties of a system that we are interested in. Sometimes it is the model that is interesting, e.g. when we need to use it for optimization or predictions.</p>
<p>At the core, regression involves minimization of some error function. The standard method is to minimize the summed squared error between the model and data. There are some benefits to this method: it is straight forward and there are well established methods to estimate the uncertainty in the parameters. However, it is known to be sensitive to outliers.</p>
<p>A variety of alternative approaches exist to reduce the influence of outliers, including minimizing the summed absolute errors, robust regression methods, and weighted regression methods. It is not always obvious what the right method to use is, this takes experience and an understanding of what you know about the model, the data, and the goals of the regression.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jupyterquiz</span> <span class="kn">import</span> <span class="n">display_quiz</span>
<span class="n">display_quiz</span><span class="p">(</span><span class="s1">&#39;.quiz.json&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div id="TUDaVvOvlEFR" data-shufflequestions="False"
               data-shuffleanswers="True"
               data-preserveresponses="false"
               data-numquestions="1000000"
               data-maxwidth="600"
               style="border-radius: 10px; text-align: left"> <style>
#TUDaVvOvlEFR {
   --jq-multiple-choice-bg: #6f78ffff;
   --jq-mc-button-bg: #fafafa;
   --jq-mc-button-border: #e0e0e0e0;
   --jq-mc-button-inset-shadow: #555555;
   --jq-many-choice-bg: #f75c03ff;
   --jq-numeric-bg: #392061ff;
   --jq-numeric-input-bg: #c0c0c0;
   --jq-numeric-input-label: #101010;
   --jq-numeric-input-shadow: #999999;
   --jq-incorrect-color: #c80202;
   --jq-correct-color: #009113;
   --jq-text-color: #fafafa;
}

.Quiz {
    max-width: 600px;
    margin-top: 15px;
    margin-left: auto;
    margin-right: auto;
    margin-bottom: 15px;
    padding-bottom: 4px;
    padding-top: 4px;
    line-height: 1.1;
    font-size: 16pt;
    border-radius: inherit;
}

.QuizCode {
    font-size: 14pt;
    margin-top: 10px;
    margin-left: 20px;
    margin-right: 20px;
}

.QuizCode>pre {
    padding: 4px;
}

.Answer {
    margin: 10px 0;
    display: grid;
    grid-template-columns: 1fr 1fr;
    grid-gap: 10px;
    border-radius: inherit;
}

.Feedback {
    font-size: 16pt;
    text-align: center;
    min-height: 2em;
}

.Input {
    align: left;
    font-size: 20pt;
}

.Input-text {
    display: block;
    margin: 10px;
    color: inherit;
    width: 140px;
    background-color: var(--jq-numeric-input-bg);
    color: var(--jq-text-color);
    padding: 5px;
    padding-left: 10px;
    font-family: inherit;
    font-size: 20px;
    font-weight: inherit;
    line-height: 20pt;
    border: none;
    border-radius: 0.2rem;
    transition: box-shadow 0.1s);
}

.Input-text:focus {
    outline: none;
    background-color: var(--jq-numeric-input-bg);
    box-shadow: 0.6rem 0.8rem 1.4rem -0.5rem var(--jq-numeric-input-shadow);
}

.MCButton {
    background: var(--jq-mc-button-bg);
    border: 1px solid var(--jq-mc-button-border);
    border-radius: inherit;
    padding: 10px;
    font-size: 16px;
    cursor: pointer;
    text-align: center;
    display: flex;
    align-items: center;
    justify-content: center;
}

.MCButton p {
    color: inherit;
}

.MultipleChoiceQn {
    padding: 10px;
    background: var(--jq-multiple-choice-bg);
    color: var(--jq-text-color);
    border-radius: inherit;
}

.ManyChoiceQn {
    padding: 10px;
    background: var(--jq-many-choice-bg);
    color: var(--jq-text-color);
    border-radius: inherit;
}

.NumericQn {
    padding: 10px;
    background: var(--jq-numeric-bg);
    color: var(--jq-text-color);
    border-radius: inherit;
}

.NumericQn p {
    color: inherit;
}

.InpLabel {
    line-height: 34px;
    float: left;
    margin-right: 10px;
    color: var(--jq-numeric-input-label);
    font-size: 15pt;
}

.incorrect {
    color: var(--jq-incorrect-color);
}

.correct {
    color: var(--jq-correct-color);
}

.correctButton {
    /*
    background: var(--jq-correct-color);
   */
    animation: correct-anim 0.6s ease;
    animation-fill-mode: forwards;
    color: var(--jq-text-color);
    box-shadow: inset 0px 0px 5px var(--jq-mc-button-inset-shadow);
    outline: none;
}

.incorrectButton {
    animation: incorrect-anim 0.8s ease;
    animation-fill-mode: forwards;
    color: var(--jq-text-color);
    box-shadow: inset 0px 0px 5px var(--jq-mc-button-inset-shadow);
    outline: none;
}

@keyframes incorrect-anim {
    100% {
        background-color: var(--jq-incorrect-color);
    }
}

@keyframes correct-anim {
    100% {
        background-color: var(--jq-correct-color);
    }
}
</style></div><script type="application/javascript">var questionsTUDaVvOvlEFR=[{"question": "The Hessian matrix obtained using scipy.minimize() can be made more accurate by", "type": "multiple_choice", "answers": [{"answer": "Decreasing the tolerance", "correct": false}, {"answer": "Using the SLSQP solver", "correct": false}, {"answer": "Increasing the tolerance", "correct": true}, {"answer": "None of the above", "correct": false}], "tag": "scipy hessian", "lecture_file": "12_nonlinear_regression"}, {"question": "The relation: Hessian_inverse = 2*Covariance is valid only in the case of ", "type": "multiple_choice", "answers": [{"answer": "minimization using sum squared errors", "correct": true}, {"answer": "minimization using absolute sum of errors", "correct": false}, {"answer": "always valid", "correct": false}, {"answer": "always valid for high tolerance solvers", "correct": false}], "tag": "hessian", "lecture_file": "12_nonlinear_regression"}, {"question": "np.linalg.inv(A) requires", "type": "multiple_choice", "answers": [{"answer": "A to be a non-singular matrix", "correct": false}, {"answer": "Determinant of A not equal to zero", "correct": false}, {"answer": "A to be a square matrix", "correct": false}, {"answer": "All of the above", "correct": true}], "tag": "numpy matrices hessian", "lecture_file": "12_nonlinear_regression"}, {"question": "Which norm regression approach among the following will be more resistant to outliers", "type": "multiple_choice", "answers": [{"answer": "L2", "correct": false}, {"answer": "L1", "correct": true}, {"answer": "Both L1 and L2 will be equally resistant", "correct": false}, {"answer": "L1.5", "correct": false}], "tag": "outliers robust_regression", "lecture_file": "12_nonlinear_regression"}, {"question": "For an array([1, 2, 3, 4, 5, 6, 7]), an additional entry of value 20 to the array, will", "type": "multiple_choice", "answers": [{"answer": "Not affect the median but will change the mean value", "correct": false}, {"answer": "Change the mean and median both, but will have less impact on the mean", "correct": false}, {"answer": "Change the mean and median both, but will have less impact on the median", "correct": true}, {"answer": "Not affect the mean but will change the median value", "correct": false}], "tag": "mean_median", "lecture_file": "12_nonlinear_regression"}, {"question": "For an array([1, 2, 3, 4, 5, 6, 7]), an additional entry of value 8 to the array, will", "type": "multiple_choice", "answers": [{"answer": "Will equally change the median and mean", "correct": true}, {"answer": "Change the mean and median both, but will have less impact on the mean", "correct": false}, {"answer": "Change the mean and median both, but will have less impact on the median", "correct": false}, {"answer": "Not affect the median or the mean", "correct": false}], "tag": "mean_median", "lecture_file": "12_nonlinear_regression"}, {"question": "Using L2 norm instead of L1 to minimize errors will affect the regression model in what way", "type": "multiple_choice", "answers": [{"answer": "The model will move towards the outliers", "correct": true}, {"answer": "The model will move away from the outliers", "correct": false}, {"answer": "The model will remain unaffected", "correct": false}, {"answer": "Can't say", "correct": false}], "tag": "robust_regression norm_regression", "lecture_file": "12_nonlinear_regression"}, {"question": "Find the median of the following set (1, 2, 3, 5, 7, 9, 13, 18, 30)", "type": "multiple_choice", "answers": [{"answer": "15.5", "correct": false}, {"answer": "7", "correct": true}, {"answer": "9.7", "correct": false}, {"answer": "13", "correct": false}], "tag": "mean_median", "lecture_file": "12_nonlinear_regression"}, {"question": "A Hessian of a scalar-valued function consists of", "type": "multiple_choice", "answers": [{"answer": "first-order partial derivatives", "correct": false}, {"answer": "first-order total derivatives", "correct": false}, {"answer": "second-order total derivatives", "correct": false}, {"answer": "second-order partial derivatives", "correct": true}], "tag": "hessian", "lecture_file": "12_nonlinear_regression"}, {"question": "To fit a model to a set of data points which were recorded using an instrument which loses precision over time, the best choice, among the following, would be to use", "type": "multiple_choice", "answers": [{"answer": "weighted regression with weights increasing for newer points", "correct": false}, {"answer": "weighted regression with weights decreasing for newer points", "correct": true}, {"answer": "regular regression without weights", "correct": false}, {"answer": "all would give the same results", "correct": false}], "tag": "robust_regression weighted_regression", "lecture_file": "12_nonlinear_regression"}];
    // Make a random ID
function makeid(length) {
    var result = [];
    var characters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz';
    var charactersLength = characters.length;
    for (var i = 0; i < length; i++) {
        result.push(characters.charAt(Math.floor(Math.random() * charactersLength)));
    }
    return result.join('');
}

// Choose a random subset of an array. Can also be used to shuffle the array
function getRandomSubarray(arr, size) {
    var shuffled = arr.slice(0), i = arr.length, temp, index;
    while (i--) {
        index = Math.floor((i + 1) * Math.random());
        temp = shuffled[index];
        shuffled[index] = shuffled[i];
        shuffled[i] = temp;
    }
    return shuffled.slice(0, size);
}

function printResponses(responsesContainer) {
    var responses=JSON.parse(responsesContainer.dataset.responses);
    var stringResponses='<B>IMPORTANT!</B>To preserve this answer sequence for submission, when you have finalized your answers: <ol> <li> Copy the text in this cell below "Answer String"</li> <li> Double click on the cell directly below the Answer String, labeled "Replace Me"</li> <li> Select the whole "Replace Me" text</li> <li> Paste in your answer string and press shift-Enter.</li><li>Save the notebook using the save icon or File->Save Notebook menu item</li></ul><br><br><br><b>Answer String:</b><br> ';
    console.log(responses);
    responses.forEach((response, index) => {
        if (response) {
            console.log(index + ': ' + response);
            stringResponses+= index + ': ' + response +"<BR>";
        }
    });
    responsesContainer.innerHTML=stringResponses;
}
function check_mc() {
    var id = this.id.split('-')[0];
    //var response = this.id.split('-')[1];
    //console.log(response);
    //console.log("In check_mc(), id="+id);
    //console.log(event.srcElement.id)           
    //console.log(event.srcElement.dataset.correct)   
    //console.log(event.srcElement.dataset.feedback)

    var label = event.srcElement;
    //console.log(label, label.nodeName);
    var depth = 0;
    while ((label.nodeName != "LABEL") && (depth < 20)) {
        label = label.parentElement;
        console.log(depth, label);
        depth++;
    }



    var answers = label.parentElement.children;

    //console.log(answers);


    // Split behavior based on multiple choice vs many choice:
    var fb = document.getElementById("fb" + id);




    if (fb.dataset.numcorrect == 1) {
        // What follows is for the saved responses stuff
        var outerContainer = fb.parentElement.parentElement;
        var responsesContainer = document.getElementById("responses" + outerContainer.id);
        if (responsesContainer) {
            //console.log(responsesContainer);
            var response = label.firstChild.innerText;
            if (label.querySelector(".QuizCode")){
                response+= label.querySelector(".QuizCode").firstChild.innerText;
            }
            console.log(response);
            //console.log(document.getElementById("quizWrap"+id));
            var qnum = document.getElementById("quizWrap"+id).dataset.qnum;
            console.log("Question " + qnum);
            //console.log(id, ", got numcorrect=",fb.dataset.numcorrect);
            var responses=JSON.parse(responsesContainer.dataset.responses);
            console.log(responses);
            responses[qnum]= response;
            responsesContainer.setAttribute('data-responses', JSON.stringify(responses));
            printResponses(responsesContainer);
        }
        // End code to preserve responses
        
        for (var i = 0; i < answers.length; i++) {
            var child = answers[i];
            //console.log(child);
            child.className = "MCButton";
        }



        if (label.dataset.correct == "true") {
            // console.log("Correct action");
            if ("feedback" in label.dataset) {
                fb.textContent = jaxify(label.dataset.feedback);
            } else {
                fb.textContent = "Correct!";
            }
            label.classList.add("correctButton");

            fb.className = "Feedback";
            fb.classList.add("correct");

        } else {
            if ("feedback" in label.dataset) {
                fb.textContent = jaxify(label.dataset.feedback);
            } else {
                fb.textContent = "Incorrect -- try again.";
            }
            //console.log("Error action");
            label.classList.add("incorrectButton");
            fb.className = "Feedback";
            fb.classList.add("incorrect");
        }
    }
    else {
        var reset = false;
        var feedback;
         if (label.dataset.correct == "true") {
            if ("feedback" in label.dataset) {
                feedback = jaxify(label.dataset.feedback);
            } else {
                feedback = "Correct!";
            }
            if (label.dataset.answered <= 0) {
                if (fb.dataset.answeredcorrect < 0) {
                    fb.dataset.answeredcorrect = 1;
                    reset = true;
                } else {
                    fb.dataset.answeredcorrect++;
                }
                if (reset) {
                    for (var i = 0; i < answers.length; i++) {
                        var child = answers[i];
                        child.className = "MCButton";
                        child.dataset.answered = 0;
                    }
                }
                label.classList.add("correctButton");
                label.dataset.answered = 1;
                fb.className = "Feedback";
                fb.classList.add("correct");

            }
        } else {
            if ("feedback" in label.dataset) {
                feedback = jaxify(label.dataset.feedback);
            } else {
                feedback = "Incorrect -- try again.";
            }
            if (fb.dataset.answeredcorrect > 0) {
                fb.dataset.answeredcorrect = -1;
                reset = true;
            } else {
                fb.dataset.answeredcorrect--;
            }

            if (reset) {
                for (var i = 0; i < answers.length; i++) {
                    var child = answers[i];
                    child.className = "MCButton";
                    child.dataset.answered = 0;
                }
            }
            label.classList.add("incorrectButton");
            fb.className = "Feedback";
            fb.classList.add("incorrect");
        }
        // What follows is for the saved responses stuff
        var outerContainer = fb.parentElement.parentElement;
        var responsesContainer = document.getElementById("responses" + outerContainer.id);
        if (responsesContainer) {
            //console.log(responsesContainer);
            var response = label.firstChild.innerText;
            if (label.querySelector(".QuizCode")){
                response+= label.querySelector(".QuizCode").firstChild.innerText;
            }
            console.log(response);
            //console.log(document.getElementById("quizWrap"+id));
            var qnum = document.getElementById("quizWrap"+id).dataset.qnum;
            console.log("Question " + qnum);
            //console.log(id, ", got numcorrect=",fb.dataset.numcorrect);
            var responses=JSON.parse(responsesContainer.dataset.responses);
            if (label.dataset.correct == "true") {
                if (typeof(responses[qnum]) == "object"){
                    if (!responses[qnum].includes(response))
                        responses[qnum].push(response);
                } else{
                    responses[qnum]= [ response ];
                }
            } else {
                responses[qnum]= response;
            }
            console.log(responses);
            responsesContainer.setAttribute('data-responses', JSON.stringify(responses));
            printResponses(responsesContainer);
        }
        // End save responses stuff



        var numcorrect = fb.dataset.numcorrect;
        var answeredcorrect = fb.dataset.answeredcorrect;
        if (answeredcorrect >= 0) {
            fb.textContent = feedback + " [" + answeredcorrect + "/" + numcorrect + "]";
        } else {
            fb.textContent = feedback + " [" + 0 + "/" + numcorrect + "]";
        }


    }

    if (typeof MathJax != 'undefined') {
        var version = MathJax.version;
        console.log('MathJax version', version);
        if (version[0] == "2") {
            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        } else if (version[0] == "3") {
            MathJax.typeset([fb]);
        }
    } else {
        console.log('MathJax not detected');
    }

}

function make_mc(qa, shuffle_answers, outerqDiv, qDiv, aDiv, id) {
    var shuffled;
    if (shuffle_answers == "True") {
        //console.log(shuffle_answers+" read as true");
        shuffled = getRandomSubarray(qa.answers, qa.answers.length);
    } else {
        //console.log(shuffle_answers+" read as false");
        shuffled = qa.answers;
    }


    var num_correct = 0;



    shuffled.forEach((item, index, ans_array) => {
        //console.log(answer);

        // Make input element
        var inp = document.createElement("input");
        inp.type = "radio";
        inp.id = "quizo" + id + index;
        inp.style = "display:none;";
        aDiv.append(inp);

        //Make label for input element
        var lab = document.createElement("label");
        lab.className = "MCButton";
        lab.id = id + '-' + index;
        lab.onclick = check_mc;
        var aSpan = document.createElement('span');
        aSpan.classsName = "";
        //qDiv.id="quizQn"+id+index;
        if ("answer" in item) {
            aSpan.innerHTML = jaxify(item.answer);
            //aSpan.innerHTML=item.answer;
        }
        lab.append(aSpan);

        // Create div for code inside question
        var codeSpan;
        if ("code" in item) {
            codeSpan = document.createElement('span');
            codeSpan.id = "code" + id + index;
            codeSpan.className = "QuizCode";
            var codePre = document.createElement('pre');
            codeSpan.append(codePre);
            var codeCode = document.createElement('code');
            codePre.append(codeCode);
            codeCode.innerHTML = item.code;
            lab.append(codeSpan);
            //console.log(codeSpan);
        }

        //lab.textContent=item.answer;

        // Set the data attributes for the answer
        lab.setAttribute('data-correct', item.correct);
        if (item.correct) {
            num_correct++;
        }
        if ("feedback" in item) {
            lab.setAttribute('data-feedback', item.feedback);
        }
        lab.setAttribute('data-answered', 0);

        aDiv.append(lab);

    });

    if (num_correct > 1) {
        outerqDiv.className = "ManyChoiceQn";
    } else {
        outerqDiv.className = "MultipleChoiceQn";
    }

    return num_correct;

}
function check_numeric(ths, event) {

    if (event.keyCode === 13) {
        ths.blur();

        var id = ths.id.split('-')[0];

        var submission = ths.value;
        if (submission.indexOf('/') != -1) {
            var sub_parts = submission.split('/');
            //console.log(sub_parts);
            submission = sub_parts[0] / sub_parts[1];
        }
        //console.log("Reader entered", submission);

        if ("precision" in ths.dataset) {
            var precision = ths.dataset.precision;
            // console.log("1:", submission)
            submission = Math.round((1 * submission + Number.EPSILON) * 10 ** precision) / 10 ** precision;
            // console.log("Rounded to ", submission, " precision=", precision  );
        }


        //console.log("In check_numeric(), id="+id);
        //console.log(event.srcElement.id)           
        //console.log(event.srcElement.dataset.feedback)

        var fb = document.getElementById("fb" + id);
        fb.style.display = "none";
        fb.textContent = "Incorrect -- try again.";

        var answers = JSON.parse(ths.dataset.answers);
        //console.log(answers);

        var defaultFB = "";
        var correct;
        var done = false;
        answers.every(answer => {
            //console.log(answer.type);

            correct = false;
            // if (answer.type=="value"){
            if ('value' in answer) {
                if (submission == answer.value) {
                    if ("feedback" in answer) {
                        fb.textContent = jaxify(answer.feedback);
                    } else {
                        fb.textContent = jaxify("Correct");
                    }
                    correct = answer.correct;
                    //console.log(answer.correct);
                    done = true;
                }
                // } else if (answer.type=="range") {
            } else if ('range' in answer) {
                //console.log(answer.range);
                if ((submission >= answer.range[0]) && (submission < answer.range[1])) {
                    fb.textContent = jaxify(answer.feedback);
                    correct = answer.correct;
                    //console.log(answer.correct);
                    done = true;
                }
            } else if (answer.type == "default") {
                defaultFB = answer.feedback;
            }
            if (done) {
                return false; // Break out of loop if this has been marked correct
            } else {
                return true; // Keep looking for case that includes this as a correct answer
            }
        });

        if ((!done) && (defaultFB != "")) {
            fb.innerHTML = jaxify(defaultFB);
            //console.log("Default feedback", defaultFB);
        }

        fb.style.display = "block";
        if (correct) {
            ths.className = "Input-text";
            ths.classList.add("correctButton");
            fb.className = "Feedback";
            fb.classList.add("correct");
        } else {
            ths.className = "Input-text";
            ths.classList.add("incorrectButton");
            fb.className = "Feedback";
            fb.classList.add("incorrect");
        }

        // What follows is for the saved responses stuff
        var outerContainer = fb.parentElement.parentElement;
        var responsesContainer = document.getElementById("responses" + outerContainer.id);
        if (responsesContainer) {
            console.log(submission);
            var qnum = document.getElementById("quizWrap"+id).dataset.qnum;
            //console.log("Question " + qnum);
            //console.log(id, ", got numcorrect=",fb.dataset.numcorrect);
            var responses=JSON.parse(responsesContainer.dataset.responses);
            console.log(responses);
            if (submission == ths.value){
                responses[qnum]= submission;
            } else {
                responses[qnum]= ths.value + "(" + submission +")";
            }
            responsesContainer.setAttribute('data-responses', JSON.stringify(responses));
            printResponses(responsesContainer);
        }
        // End code to preserve responses

        if (typeof MathJax != 'undefined') {
            var version = MathJax.version;
            console.log('MathJax version', version);
            if (version[0] == "2") {
                MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
            } else if (version[0] == "3") {
                MathJax.typeset([fb]);
            }
        } else {
            console.log('MathJax not detected');
        }
        return false;
    }

}

function isValid(el, charC) {
    //console.log("Input char: ", charC);
    if (charC == 46) {
        if (el.value.indexOf('.') === -1) {
            return true;
        } else if (el.value.indexOf('/') != -1) {
            var parts = el.value.split('/');
            if (parts[1].indexOf('.') === -1) {
                return true;
            }
        }
        else {
            return false;
        }
    } else if (charC == 47) {
        if (el.value.indexOf('/') === -1) {
            if ((el.value != "") && (el.value != ".")) {
                return true;
            } else {
                return false;
            }
        } else {
            return false;
        }
    } else if (charC == 45) {
        var edex = el.value.indexOf('e');
        if (edex == -1) {
            edex = el.value.indexOf('E');
        }

        if (el.value == "") {
            return true;
        } else if (edex == (el.value.length - 1)) { // If just after e or E
            return true;
        } else {
            return false;
        }
    } else if (charC == 101) { // "e"
        if ((el.value.indexOf('e') === -1) && (el.value.indexOf('E') === -1) && (el.value.indexOf('/') == -1)) {
            // Prev symbol must be digit or decimal point:
            if (el.value.slice(-1).search(/\d/) >= 0) {
                return true;
            } else if (el.value.slice(-1).search(/\./) >= 0) {
                return true;
            } else {
                return false;
            }
        } else {
            return false;
        }
    } else {
        if (charC > 31 && (charC < 48 || charC > 57))
            return false;
    }
    return true;
}

function numeric_keypress(evnt) {
    var charC = (evnt.which) ? evnt.which : evnt.keyCode;

    if (charC == 13) {
        check_numeric(this, evnt);
    } else {
        return isValid(this, charC);
    }
}





function make_numeric(qa, outerqDiv, qDiv, aDiv, id) {



    //console.log(answer);


    outerqDiv.className = "NumericQn";
    aDiv.style.display = 'block';

    var lab = document.createElement("label");
    lab.className = "InpLabel";
    lab.textContent = "Type numeric answer here:";
    aDiv.append(lab);

    var inp = document.createElement("input");
    inp.type = "text";
    //inp.id="input-"+id;
    inp.id = id + "-0";
    inp.className = "Input-text";
    inp.setAttribute('data-answers', JSON.stringify(qa.answers));
    if ("precision" in qa) {
        inp.setAttribute('data-precision', qa.precision);
    }
    aDiv.append(inp);
    //console.log(inp);

    //inp.addEventListener("keypress", check_numeric);
    //inp.addEventListener("keypress", numeric_keypress);
    /*
    inp.addEventListener("keypress", function(event) {
        return numeric_keypress(this, event);
    }
                        );
                        */
    //inp.onkeypress="return numeric_keypress(this, event)";
    inp.onkeypress = numeric_keypress;
    inp.onpaste = event => false;

    inp.addEventListener("focus", function (event) {
        this.value = "";
        return false;
    }
    );


}
function jaxify(string) {
    var mystring = string;

    var count = 0;
    var loc = mystring.search(/([^\\]|^)(\$)/);

    var count2 = 0;
    var loc2 = mystring.search(/([^\\]|^)(\$\$)/);

    //console.log(loc);

    while ((loc >= 0) || (loc2 >= 0)) {

        /* Have to replace all the double $$ first with current implementation */
        if (loc2 >= 0) {
            if (count2 % 2 == 0) {
                mystring = mystring.replace(/([^\\]|^)(\$\$)/, "$1\\[");
            } else {
                mystring = mystring.replace(/([^\\]|^)(\$\$)/, "$1\\]");
            }
            count2++;
        } else {
            if (count % 2 == 0) {
                mystring = mystring.replace(/([^\\]|^)(\$)/, "$1\\(");
            } else {
                mystring = mystring.replace(/([^\\]|^)(\$)/, "$1\\)");
            }
            count++;
        }
        loc = mystring.search(/([^\\]|^)(\$)/);
        loc2 = mystring.search(/([^\\]|^)(\$\$)/);
        //console.log(mystring,", loc:",loc,", loc2:",loc2);
    }

    //console.log(mystring);
    return mystring;
}


function show_questions(json, mydiv) {
    console.log('show_questions');
    //var mydiv=document.getElementById(myid);
    var shuffle_questions = mydiv.dataset.shufflequestions;
    var num_questions = mydiv.dataset.numquestions;
    var shuffle_answers = mydiv.dataset.shuffleanswers;
    var max_width = mydiv.dataset.maxwidth;

    if (num_questions > json.length) {
        num_questions = json.length;
    }

    var questions;
    if ((num_questions < json.length) || (shuffle_questions == "True")) {
        //console.log(num_questions+","+json.length);
        questions = getRandomSubarray(json, num_questions);
    } else {
        questions = json;
    }

    //console.log("SQ: "+shuffle_questions+", NQ: " + num_questions + ", SA: ", shuffle_answers);

    // Iterate over questions
    questions.forEach((qa, index, array) => {
        //console.log(qa.question); 

        var id = makeid(8);
        //console.log(id);


        // Create Div to contain question and answers
        var iDiv = document.createElement('div');
        //iDiv.id = 'quizWrap' + id + index;
        iDiv.id = 'quizWrap' + id;
        iDiv.className = 'Quiz';
        iDiv.setAttribute('data-qnum', index);
        iDiv.style.maxWidth  =max_width+"px";
        mydiv.appendChild(iDiv);
        // iDiv.innerHTML=qa.question;
        
        var outerqDiv = document.createElement('div');
        outerqDiv.id = "OuterquizQn" + id + index;
        // Create div to contain question part
        var qDiv = document.createElement('div');
        qDiv.id = "quizQn" + id + index;
        
        if (qa.question) {
            iDiv.append(outerqDiv);

            //qDiv.textContent=qa.question;
            qDiv.innerHTML = jaxify(qa.question);
            outerqDiv.append(qDiv);
        }

        // Create div for code inside question
        var codeDiv;
        if ("code" in qa) {
            codeDiv = document.createElement('div');
            codeDiv.id = "code" + id + index;
            codeDiv.className = "QuizCode";
            var codePre = document.createElement('pre');
            codeDiv.append(codePre);
            var codeCode = document.createElement('code');
            codePre.append(codeCode);
            codeCode.innerHTML = qa.code;
            outerqDiv.append(codeDiv);
            //console.log(codeDiv);
        }


        // Create div to contain answer part
        var aDiv = document.createElement('div');
        aDiv.id = "quizAns" + id + index;
        aDiv.className = 'Answer';
        iDiv.append(aDiv);

        //console.log(qa.type);

        var num_correct;
        if ((qa.type == "multiple_choice") || (qa.type == "many_choice") ) {
            num_correct = make_mc(qa, shuffle_answers, outerqDiv, qDiv, aDiv, id);
            if ("answer_cols" in qa) {
                //aDiv.style.gridTemplateColumns = 'auto '.repeat(qa.answer_cols);
                aDiv.style.gridTemplateColumns = 'repeat(' + qa.answer_cols + ', 1fr)';
            }
        } else if (qa.type == "numeric") {
            //console.log("numeric");
            make_numeric(qa, outerqDiv, qDiv, aDiv, id);
        }


        //Make div for feedback
        var fb = document.createElement("div");
        fb.id = "fb" + id;
        //fb.style="font-size: 20px;text-align:center;";
        fb.className = "Feedback";
        fb.setAttribute("data-answeredcorrect", 0);
        fb.setAttribute("data-numcorrect", num_correct);
        iDiv.append(fb);


    });
    var preserveResponses = mydiv.dataset.preserveresponses;
    console.log(preserveResponses);
    console.log(preserveResponses == "true");
    if (preserveResponses == "true") {
        console.log(preserveResponses);
        // Create Div to contain record of answers
        var iDiv = document.createElement('div');
        iDiv.id = 'responses' + mydiv.id;
        iDiv.className = 'JCResponses';
        // Create a place to store responses as an empty array
        iDiv.setAttribute('data-responses', '[]');

        // Dummy Text
        iDiv.innerHTML="<b>Select your answers and then follow the directions that will appear here.</b>"
        //iDiv.className = 'Quiz';
        mydiv.appendChild(iDiv);
    }
//console.log("At end of show_questions");
    if (typeof MathJax != 'undefined') {
        console.log("MathJax version", MathJax.version);
        var version = MathJax.version;
        setTimeout(function(){
            var version = MathJax.version;
            console.log('After sleep, MathJax version', version);
            if (version[0] == "2") {
                MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
            } else if (version[0] == "3") {
                MathJax.typeset([mydiv]);
            }
        }, 500);
if (typeof version == 'undefined') {
        } else
        {
            if (version[0] == "2") {
                MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
            } else if (version[0] == "3") {
                MathJax.typeset([mydiv]);
            } else {
                console.log("MathJax not found");
            }
        }
    }
    return false;
}
/* This is to handle asynchrony issues in loading Jupyter notebooks
           where the quiz has been previously run. The Javascript was generally
           being run before the div was added to the DOM. I tried to do this
           more elegantly using Mutation Observer, but I didn't get it to work.

           Someone more knowledgeable could make this better ;-) */

        function try_show() {
          if(document.getElementById("TUDaVvOvlEFR")) {
            show_questions(questionsTUDaVvOvlEFR,  TUDaVvOvlEFR); 
          } else {
             setTimeout(try_show, 200);
          }
        };
    
        {
        // console.log(element);

        //console.log("TUDaVvOvlEFR");
        // console.log(document.getElementById("TUDaVvOvlEFR"));

        try_show();
        }
        </script></div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./lectures/12-nonlinear-regression"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="../11-regression/11-regression.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Introduction to nonlinear regression</p>
      </div>
    </a>
    <a class="right-next"
       href="../13-constrained-optimization/13-constrained-optimization.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Constrained minimization</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Uncertainty estimates from curvefit and scipy.optimize.minimize</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#effects-of-outliers-on-regression">Effects of outliers on regression</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#minimizing-the-summed-absolute-errors">Minimizing the summed absolute errors</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#robust-regression-approaches">Robust regression approaches</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#least-median-regression">Least Median regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#weighted-nonlinear-regression">Weighted nonlinear regression</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By John Kitchin
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>