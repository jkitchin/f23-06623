{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2dUnK-QUtD7"
   },
   "source": [
    "[TOC](../toc.ipynb)\n",
    "\n",
    "Applications of automatic differentiation\n",
    "==========================================\n",
    "\n",
    "- KEYWORDS: jax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](autograd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vpG3qIGUtEA"
   },
   "source": [
    "# Mathematical, scientific and engineering applications of jax\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCteuSSUUtED"
   },
   "source": [
    "## Evaluating line integrals\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82eVMZyxUtEF"
   },
   "source": [
    "A line integral is an integral of a function along a curve in space. We usually represent the curve by a parametric equation, e.g. $\\mathbf{r}(t) = [x(t), y(t), z(t)] = x(t)\\mathbf{i} + y(t)\\mathbf{j} + z(t)\\mathbf{k}$.  So, in general the curve will be a vector function, and the function we want to integrate will also be a vector function.\n",
    "\n",
    "Then, we can write the line integral definition as:\n",
    "\n",
    "$\\int_C \\mathbf{F(r)} \\cdot d\\mathbf{r} = \\int_a^b \\mathbf{F}(\\mathbf{r}(t)) \\cdot \\mathbf{r'}(t) dt$ where $\\mathbf{r'}(t) = \\frac{d\\mathbf{r}}{dt}$. This integrand is a scalar function, because of the dot product.\n",
    "\n",
    "The following examples are adapted from Chapter 10 in Advanced Engineering Mathematics by Kreysig.\n",
    "\n",
    "The first example is the evaluation of  a line integral in the plane. We want to evaluate the integral of $\\mathbf{F(r)}=[-y, -xy]$ on the curve $\\mathbf{r(t)}=[-sin(t), cos(t)]$ from t=0 to t = &pi;/2. The answer in the book is given as 0.4521. Here we evaluate this numerically, using jax for the relevant derivative. Since the curve has multiple outputs, we have to use the jacobian function to get the derivatives. After that, it is a simple bit of matrix multiplication, and a call to the quad function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 139,
     "status": "ok",
     "timestamp": 1637071578450,
     "user": {
      "displayName": "John Kitchin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14782011281593705406"
     },
     "user_tz": 300
    },
    "id": "JjNJdVdUTgnX"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jax'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m      3\u001b[0m config\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjax_enable_x64\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jax'"
     ]
    }
   ],
   "source": [
    "from jax.config import config\n",
    "\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import jax.numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1637241403363,
     "user": {
      "displayName": "John Kitchin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14782011281593705406"
     },
     "user_tz": 300
    },
    "id": "cfduBVAqVJzL",
    "outputId": "4c18c2b8-034a-4e7f-8fde-ff3edc083773"
   },
   "outputs": [],
   "source": [
    "t = np.linspace(0, np.pi / 2)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = -np.sin(t)\n",
    "y = np.cos(t)\n",
    "plt.plot(x[0], y[0], \"go\")\n",
    "plt.plot(x[-1], y[-1], \"rs\")\n",
    "plt.plot(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import jacrev\n",
    "from scipy.integrate import quad\n",
    "\n",
    "\n",
    "def F(X):\n",
    "    x, y = X\n",
    "    return np.array([-y, -x * y])\n",
    "\n",
    "\n",
    "def r(t):\n",
    "    return np.array([-np.sin(t), np.cos(t)])\n",
    "\n",
    "\n",
    "drdt = jacrev(r)  # programming with a derivative\n",
    "\n",
    "\n",
    "def integrand(t):\n",
    "    return F(r(t)) @ drdt(t)\n",
    "\n",
    "\n",
    "I, e = quad(integrand, 0.0, np.pi / 2)\n",
    "print(f\"The integral is {I:1.4f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 96,
     "status": "ok",
     "timestamp": 1637241474779,
     "user": {
      "displayName": "John Kitchin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14782011281593705406"
     },
     "user_tz": 300
    },
    "id": "3NFcXzAOW6Rj",
    "outputId": "095de448-f62c-4f34-ab30-d204d1e0ba4d"
   },
   "outputs": [],
   "source": [
    "r(0), drdt(0.0), F(r(0))  # checking what these all return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 96,
     "status": "ok",
     "timestamp": 1637241545039,
     "user": {
      "displayName": "John Kitchin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14782011281593705406"
     },
     "user_tz": 300
    },
    "id": "JHtqDoDhMwG0",
    "outputId": "c5869ffd-11fb-49d3-fc63-d82cb604f7e0"
   },
   "outputs": [],
   "source": [
    "drdt(1.0) @ F(r(1.0))  # we are integrating (Accumulating) this value along the path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sai4Xh5CUtEa"
   },
   "source": [
    "We get the same result as the analytical solution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wuIvVkTYUtEc"
   },
   "source": [
    "## Constrained optimization with Lagrange multipliers and jax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wr_PIOUiUtEf"
   },
   "source": [
    "Constrained optimization is common in engineering problems solving. A prototypical example (from Greenberg, Advanced Engineering Mathematics, Ch 13.7) is to find the point on a plane that is closest to the origin. The plane is defined by the equation $2x - y + z = 3$, and we seek to minimize $x^2 + y^2 + z^2$ subject to the equality constraint defined by the plane. `scipy.optimize.minimize` provides a pretty convenient interface to solve a problem like this, as shown here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 114,
     "status": "ok",
     "timestamp": 1637241941033,
     "user": {
      "displayName": "John Kitchin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14782011281593705406"
     },
     "user_tz": 300
    },
    "id": "3Gx5pKlGUtEg",
    "outputId": "544df96a-0b35-44cd-9bc6-da308dace6bd"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def objective(X):\n",
    "    x, y, z = X\n",
    "    return x**2 + y**2 + z**2\n",
    "\n",
    "\n",
    "def eq(X):\n",
    "    x, y, z = X\n",
    "    return 2 * x - y + z - 3\n",
    "\n",
    "\n",
    "sol = minimize(objective, [1, -0.0, 0.0], constraints={\"type\": \"eq\", \"fun\": eq})\n",
    "sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZN1UTVuUtEt"
   },
   "source": [
    "I like the minimize function a lot, although I do not love how the constraints are provided.\n",
    "Sometimes, it might be desirable to go back to basics though, especially if you are unaware of the `minimize` function or perhaps suspect it is not working right and want an independent answer. Next we look at how to construct this constrained optimization problem using Lagrange multipliers. This converts the problem into an augmented unconstrained optimization problem we can use `root` on. The gist of this method is we formulate a new problem:\n",
    "\n",
    "$F(L) = f(X) - \\lambda g(X)$\n",
    "\n",
    "and then solve the simultaneous resulting equations:\n",
    "\n",
    "$F_x(L) = F_y(L) = F_z(L) = g(X) = 0$ where $F_x$ is the derivative of $F(L)$ with respect to $x$, and $g(X)$ is the equality constraint written so it is equal to zero. Since we end up with four equations that equal zero, we can simply use `root` to get the solution. Many [years ago](http://kitchingroup.cheme.cmu.edu/blog/2013/02/03/Using-Lagrange-multipliers-in-optimization/) I used a finite difference approximation to the derivatives. Today we use jax to get the desired derivatives. Here it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 103,
     "status": "ok",
     "timestamp": 1637242462845,
     "user": {
      "displayName": "John Kitchin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14782011281593705406"
     },
     "user_tz": 300
    },
    "id": "mW2C2AjHZR9I",
    "outputId": "96e8db94-4378-422d-a19f-c55a6018347c"
   },
   "outputs": [],
   "source": [
    "from jax import grad\n",
    "\n",
    "\n",
    "def F(L):\n",
    "    \"Augmented Lagrange function\"\n",
    "    x, y, z, _lambda = L\n",
    "    return objective([x, y, z]) - _lambda * eq([x, y, z])\n",
    "\n",
    "\n",
    "F([1.0, -0.5, 0.5, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 96,
     "status": "ok",
     "timestamp": 1637242350581,
     "user": {
      "displayName": "John Kitchin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14782011281593705406"
     },
     "user_tz": 300
    },
    "id": "kPXVOBf0Zb9w",
    "outputId": "78a442b7-1c30-4441-a79c-62aff20198a4"
   },
   "outputs": [],
   "source": [
    "# Gradients of the Lagrange function\n",
    "dfdL = grad(F, 0)\n",
    "dfdL(np.array([0.0, 0.0, 0.0, 1.0]))\n",
    "\n",
    "# Fx, Fy, Fz, dF/dlambda\n",
    "# X has 4 elements so grad(F) returns 4 derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 98,
     "status": "ok",
     "timestamp": 1637242399426,
     "user": {
      "displayName": "John Kitchin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14782011281593705406"
     },
     "user_tz": 300
    },
    "id": "9s9C1MtiUtEw",
    "outputId": "eaf761e1-2cfd-47eb-d54f-279204596f74"
   },
   "outputs": [],
   "source": [
    "# Find L that returns all zeros in this function.\n",
    "def obj(L):\n",
    "    x, y, z, _lambda = L\n",
    "    dFdx, dFdy, dFdz, dFdlam = dfdL(L)\n",
    "    return [dFdx, dFdy, dFdz, eq([x, y, z])]\n",
    "\n",
    "\n",
    "from scipy.optimize import root\n",
    "\n",
    "x, y, z, _lam = root(obj, [0.0, 0.0, 0.0, 1.0])\n",
    "print(f\"The answer is at {x, y, z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 103,
     "status": "ok",
     "timestamp": 1637242418547,
     "user": {
      "displayName": "John Kitchin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14782011281593705406"
     },
     "user_tz": 300
    },
    "id": "oaY1NkLCQKLW",
    "outputId": "7c9ad59d-9bc8-466b-def3-b2abc74094f8"
   },
   "outputs": [],
   "source": [
    "_lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1637242423808,
     "user": {
      "displayName": "John Kitchin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14782011281593705406"
     },
     "user_tz": 300
    },
    "id": "gKxVGJYGa5Sb",
    "outputId": "71b35d7b-8ba3-4acc-c13c-653260dd64d5"
   },
   "outputs": [],
   "source": [
    "obj([x, y, z, _lam])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EBLk982zUtE6"
   },
   "source": [
    "That is the same answer as before. Note we have still relied on some black box solver inside of root (instead of inside minimize), but it might be more clear what problem we are solving (e.g. finding zeros). It takes a bit more work to set this up, since we have to construct the augmented function, but jax makes it pretty convenient to set up the final objective function we want to solve.\n",
    "\n",
    "How do we know we are at a minimum? We can check that the Hessian is positive definite in the original function we wanted to minimize. You can see here the array is positive definite, e.g. all the eigenvalues are positive. jax makes this easy too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 117,
     "status": "ok",
     "timestamp": 1637242552688,
     "user": {
      "displayName": "John Kitchin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14782011281593705406"
     },
     "user_tz": 300
    },
    "id": "pKm-nGffUtE8",
    "outputId": "a5226d9c-7f36-4067-b235-015639516fec"
   },
   "outputs": [],
   "source": [
    "from jax import hessian\n",
    "\n",
    "h = hessian(objective, 0)\n",
    "h(np.array([x, y, z]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8tbSWpoUtFH"
   },
   "source": [
    "In case it isn't evident from that structure that the eigenvalues are all positive, here we compute them:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97,
     "status": "ok",
     "timestamp": 1637242581449,
     "user": {
      "displayName": "John Kitchin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14782011281593705406"
     },
     "user_tz": 300
    },
    "id": "R1N2Bq5PUtFJ",
    "outputId": "e2a020a0-b030-4e97-cfa8-6ee220f1eac6"
   },
   "outputs": [],
   "source": [
    "np.linalg.eig(h(np.array([x, y, z])))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wz2cy2wFUtFV"
   },
   "source": [
    "## Getting derivatives from implicit functions with jax\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KY2GyLbhR9jC"
   },
   "source": [
    "This equation is explict: y = f(x)\n",
    "\n",
    "This one is implicit: $sin y = e ^ {x * y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2XwqBKrUtFX"
   },
   "source": [
    "If we have an implicit function: $f(x, y(x)) = 0$, but we want to compute the derivative $dy/dx$ we can use the chain rule to derive:\n",
    "\n",
    "$\\frac{df}{dx} + \\frac{df}{dy} * \\frac{dy}{dx} = 0$\n",
    "\n",
    "We can then solve for $dy/dx$:\n",
    "\n",
    "$\\frac{dy}{dx} = -\\frac{\\frac{df}{dx}}{\\frac{df}{dy}}$\n",
    "\n",
    "to get the desired derivative. The interesting point of this is that we can get the two derivatives on the right hand side of this equation using automatic differentiation of the function $f(x, y)$! There are a few examples of analytical approaches to derivatives from implicit functions [here](https://www.math.ucdavis.edu/~kouba/CalcOneDIRECTORY/implicitdiffdirectory/ImplicitDiff.html) we will use for example.\n",
    "\n",
    "In the following examples, we will assume that $y$ is a function of $x$ and that $x$ is independent. We will consider a series of implicit equations, compute $dy/dx$ using jax from the formula above, and compare them to the analytical results in the web page referenced above.\n",
    "\n",
    "The $dy/dx$ functions generally depend on both $x$, and $y$. Technically, these are the derivatives along the curve $y(x)$, but since we can evaluate them at any points, we will use some random points for $x$ and $y$ to test for equality between the analytical derivatives and the jax derivatives. This isn't a rigorous proof of equality, but it is the only thing that makes sense to do for now. It is assumed that if these points are ok, all the others are too. That might be a broad claim, since we only sample $x$ and $y$ from 0 to 1 here but the approach is general. Here are the imports and the random test points for all the examples that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vH6fj0_nUtFa"
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "key = jax.random.PRNGKey(42)\n",
    "\n",
    "xr = jax.random.uniform(key, (50,))\n",
    "yr = jax.random.uniform(key+1, (50,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zpn6DhiaUtFl"
   },
   "source": [
    "Next we consider $x^3 + y^3 = 4$ as our implicit function.\n",
    "\n",
    "$f(x, y) = x^3 + y^3 - 4 = 0$\n",
    "\n",
    "$df/dx = 3 x^2$\n",
    "\n",
    "$df/dy = 3 y^2$\n",
    "\n",
    "so $dy/dx = -x^2 / y^2$ for comparison.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122,
     "status": "ok",
     "timestamp": 1637243408082,
     "user": {
      "displayName": "John Kitchin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14782011281593705406"
     },
     "user_tz": 300
    },
    "id": "N1srCN5gUtFm",
    "outputId": "a42981bd-9ab7-49c9-dcb7-071179e4fa71"
   },
   "outputs": [],
   "source": [
    "def f1(x, y):\n",
    "    return x**3 + y**3 - 4\n",
    "\n",
    "\n",
    "df1dx = grad(f1, 0)  # x is arg 0 in position\n",
    "df1dy = grad(f1, 1)  # y is arg 1\n",
    "\n",
    "\n",
    "def dydx(x, y):\n",
    "    return -df1dx(x, y) / df1dy(x, y)\n",
    "\n",
    "from jax import vmap\n",
    "\n",
    "np.allclose(-(xr**2) / yr**2,  # analytical derivative\n",
    "            vmap(dydx)(xr, yr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1637243427450,
     "user": {
      "displayName": "John Kitchin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14782011281593705406"
     },
     "user_tz": 300
    },
    "id": "ZutxI2kJd1-T",
    "outputId": "0c4ff638-d472-470c-e3c1-65c80a4b48c2"
   },
   "outputs": [],
   "source": [
    "plt.plot(xr, -(xr**2) / yr**2, \"ro\", label=\"analytical\")\n",
    "plt.plot(xr, [dydx(_xr, _yr) for _xr, _yr in zip(xr, yr)], \"b.\", label=\"jax\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H42uf513UtF9"
   },
   "source": [
    "The output of True means the jax results and the analytical results are \"all close\", i.e. within a tolerance the results are the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOGlTdXHUtGI"
   },
   "source": [
    "# Scientific applications\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gv03Kq7IUtGK"
   },
   "source": [
    "## Compressibility variation from an implicit equation of state\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzejr80zUtGM"
   },
   "source": [
    "There are two ways to explore how some property varies with some parameter. One is if you have an equation relating them, you simply solve it many times for each parameter. Another is if you can derive an equation for how the property changes with parameter changes, then you have an ODE you can integrate. We explore that here. We will use the van der Waal equation of state to derive an equation for how the compressibility changes with the reduced pressure.\n",
    "\n",
    "The general strategy to compute the compressibility as a function of pressure is to integrate $dV / dP_r$ over a range of $P_r$ to get the molar volume as a function of $P_r$, and then to directly compute the compressibility from $Z = PV/(RT)$.\n",
    "\n",
    "To use this approach we need to get $dV / dP_r$ from the van der Waal equation. Here, we follow the work in the previous section to get the derivative from the implicit form of the van der Waal equation:\n",
    "\n",
    "$f(V, P_r, T_r) = \\frac{R Tr * Tc}{V - b} - \\frac{a}{V^2} - P_r Pc = 0$\n",
    "\n",
    "We can get\n",
    "\n",
    "$dV/dP_r = (-df/dP_r) / (df/dV)$\n",
    "\n",
    "and the two derivatives on the right can be found easily by automatic differentiation. First, we express the van der Waal equation in implicit form, with the variables as $V, P_r, T_r$. Only two of those variables are independent; if you define two of them you can compute the third one using a tool like root.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 108,
     "status": "ok",
     "timestamp": 1637246424766,
     "user": {
      "displayName": "John Kitchin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14782011281593705406"
     },
     "user_tz": 300
    },
    "id": "Uz7rgMuXUtGQ"
   },
   "outputs": [],
   "source": [
    "R = 0.08206  # gas constant\n",
    "Pc = 72.9\n",
    "Tc = 304.2\n",
    "\n",
    "a = 27 * R**2 * Tc**2 / (Pc * 64)\n",
    "b = R * Tc / (8 * Pc)\n",
    "\n",
    "Tr = 1.1  # Constant for this example, reduced temperature\n",
    "\n",
    "\n",
    "def f(V, Pr, Tr):\n",
    "    return R * Tr * Tc / (V - b) - a / V**2 - Pr * Pc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmtwueB4UtGb"
   },
   "source": [
    "Now, if we want to know how does the volume vary with $P_r$, we need to derive the derivative $dV/dP_r$, and then integrate it. Here we use jax to define the derivatives, and then we define a function that uses them. Note the arguments in the function dVdPr are in an order that anticipates we want to integrate it in solve\\_ivp, to get a function $V(P_r)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1637246426610,
     "user": {
      "displayName": "John Kitchin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14782011281593705406"
     },
     "user_tz": 300
    },
    "id": "YXndamwMUtGd"
   },
   "outputs": [],
   "source": [
    "dfdPr = grad(f, 1)  # derivative of f with respect to arg at index=1: Pr\n",
    "dfdV = grad(f, 0)  # derivative of f with respect to arg at index=0: V\n",
    "\n",
    "\n",
    "def dVdPr(Pr, V):\n",
    "    V = V.squeeze() # V may be a 1-d array, so we squeeze that off so we have a scalar output.\n",
    "    return -dfdPr(V, Pr, Tr) / dfdV(V, Pr, Tr)  # Tr is a constant in here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fF5IvzmRUtGn"
   },
   "source": [
    "Now, we need an initial condition to start the integration from. We want the volume at $P_r=0.1$. We have to use `root` for this, or some other method that tells you want is the volume at $P_r=0.1$. We can pass the values of $P_r$ and $T_R$ as arguments to our implicit function. Since $V$ is the first argument, we can directly solve our implicit function. Otherwise you would have to define a helper objective function to use with root.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 101,
     "status": "ok",
     "timestamp": 1637244611735,
     "user": {
      "displayName": "John Kitchin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14782011281593705406"
     },
     "user_tz": 300
    },
    "id": "ewptr3gVUtGp",
    "outputId": "85a39565-a839-4a5e-e7a2-ef5865eac885"
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import root\n",
    "\n",
    "sol = root(f, 3.5, args=(0.1, 1.1))\n",
    "sol.x  # V0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTxI6o5MUtGy"
   },
   "source": [
    "Finally, we are ready to integrate the ODE, and plot the solution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "executionInfo": {
     "elapsed": 634,
     "status": "ok",
     "timestamp": 1637244673901,
     "user": {
      "displayName": "John Kitchin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14782011281593705406"
     },
     "user_tz": 300
    },
    "id": "EuJnuKQKUtG0",
    "outputId": "9a493edc-8a6d-44a9-91a4-88c9e0b2527e"
   },
   "outputs": [],
   "source": [
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "Pr_span = (0.1, 10)\n",
    "Pr_eval, h = np.linspace(*Pr_span, retstep=True)\n",
    "\n",
    "V0, = sol.x\n",
    "\n",
    "sol = solve_ivp(dVdPr, Pr_span, (V0,), max_step=h)\n",
    "print(sol.message)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Pr = sol.t  # the P_r steps used in the solution\n",
    "V = sol.y[0]  # V(P_r) from the solution\n",
    "\n",
    "Z = Pr * Pc * V / (R * Tr * Tc)  # Compressibility Z(P_r)\n",
    "\n",
    "plt.plot(Pr, Z)\n",
    "plt.xlabel(\"$P_r$\")\n",
    "plt.ylabel(\"Z\")\n",
    "plt.xlim([0, 10])\n",
    "plt.ylim([0, 2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFVl16cVUtG8"
   },
   "source": [
    "There are several advantages of doing this over iteratively solving with root. The biggest one is no initial guesses! It is also faster. What do you think would happen if there were multiple roots in the equation?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhrdxiqaUtG9"
   },
   "source": [
    "## Computing the pressure from a solid equation of state\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhR9nSuhUtG-"
   },
   "source": [
    "A solid equation of state describes the energy of a solid under isotropic strain. We can readily compute the pressure at a particular volume from the equation:\n",
    "\n",
    "$P = -\\frac{dE}{dV}$\n",
    "\n",
    "We just need the derivative of this equation:\n",
    "\n",
    "$E = E_0+\\frac{B_0 V}{B'_0}\\left[\\frac{(V_0/V)^{B'_0}}{B'_0-1}+1\\right]-\\frac{V_0 B_0}{B'_0-1}$\n",
    "\n",
    "We use jax to get it for us.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108,
     "status": "ok",
     "timestamp": 1637245177270,
     "user": {
      "displayName": "John Kitchin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14782011281593705406"
     },
     "user_tz": 300
    },
    "id": "EoenDt4gUtG_",
    "outputId": "b4bdd82b-2317-409f-dfff-ab1968da8898"
   },
   "outputs": [],
   "source": [
    "E0, B0, BP, V0 = -56.466, 0.49, 4.753, 16.573\n",
    "\n",
    "\n",
    "def Murnaghan(vol):\n",
    "    E = (E0\n",
    "         + B0 * vol / BP * (((V0 / vol) ** BP) / (BP - 1.0) + 1.0)\n",
    "         - V0 * B0 / (BP - 1.0))\n",
    "    return E\n",
    "\n",
    "\n",
    "def P(vol):\n",
    "    dEdV = grad(Murnaghan)\n",
    "    return -dEdV(vol) * 160.21773  # in Gpa\n",
    "\n",
    "\n",
    "print(P(V0))  # Pressure at the minimum in energy is zero\n",
    "print(P(0.99 * V0))  # Compressed\n",
    "print(P(1.01 * V0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "executionInfo": {
     "elapsed": 243,
     "status": "ok",
     "timestamp": 1637245217672,
     "user": {
      "displayName": "John Kitchin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14782011281593705406"
     },
     "user_tz": 300
    },
    "id": "Ipt0YfC_auZe",
    "outputId": "f5e37974-385e-4cd8-d696-728071189a32"
   },
   "outputs": [],
   "source": [
    "V = np.linspace(15, 18)\n",
    "plt.plot(V, Murnaghan(V));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lQQ55O_UtHE"
   },
   "source": [
    "So it takes positive pressure to compress the system, as expected, and at the minimum the pressure is equal to zero. Seems pretty clear jax is better than deriving the required pressure derivative.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tu-BsQiUtHF"
   },
   "source": [
    "## Sensitivity analysis using automatic differentiation in Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EN31IolNUtHG"
   },
   "source": [
    "This [paper](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.428.6699&rep=rep1&type=pdf) describes how sensitivity analysis requires access to the derivatives of a function. Say, for example we have a function describing the time evolution of the concentration of species A:\n",
    "\n",
    "$[A] = \\frac{[A]_0}{k_1 + k_{-1}} (k_1 e^{(-(k_1 + k_{-1})t)} + k_{-1})$\n",
    "\n",
    "The local sensitivity of the concentration of A to the parameters $k1$ and $k_1$ are defined as $\\frac{\\partial A}{\\partial k_1}$ and $\\frac{\\partial A}{\\partial k_{-1}}$. Our goal is to plot the sensitivity as a function of time. We could derive those derivatives, but we will use auto-differentiation instead through the jax package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1637245625638,
     "user": {
      "displayName": "John Kitchin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14782011281593705406"
     },
     "user_tz": 300
    },
    "id": "H02jTLkKUtHH",
    "outputId": "49ef6a11-3066-4119-d5fe-7b6ffac16448"
   },
   "outputs": [],
   "source": [
    "A0 = 1.0\n",
    "\n",
    "def A(t, k1, k_1):\n",
    "    return A0 / (k1 + k_1) * (k1 * np.exp(-(k1 + k_1) * t) + k_1)\n",
    "\n",
    "t = np.linspace(0, 0.5)\n",
    "\n",
    "k1 = 3.0\n",
    "k_1 = 3.0\n",
    "plt.plot(t, A(t, k1, k_1), label=\"A\")\n",
    "plt.plot(t, A0 - A(t, k1, k_1), \"--\", color=\"orange\", label=\"B\")\n",
    "plt.xlim([0, 0.5])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"A,B\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnB_F-mZUtHL"
   },
   "source": [
    "The figure above reproduces Fig. 1 from the paper referenced above.  Next, we use jax to get the derivatives. We need the derivative of the function with respect to the second and third arguments; the default is the first argument. Second, we want to evaluate this derivative at each time value.  Finally, to reproduce Figure 2a, we plot the absolute value of the sensitivities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 419,
     "status": "ok",
     "timestamp": 1637245695726,
     "user": {
      "displayName": "John Kitchin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14782011281593705406"
     },
     "user_tz": 300
    },
    "id": "Z5xWhiqWUtHL",
    "outputId": "a8c080aa-7e78-47df-c689-6fdbabddbdc0"
   },
   "outputs": [],
   "source": [
    "fdAdk1 = jacrev(A, 1)  # k1\n",
    "fdAdk_1 = jacrev(A, 2)  # k_1\n",
    "\n",
    "dAdk1 = fdAdk1(t, k1, k_1) \n",
    "dAdk_1 = fdAdk_1(t, k1, k_1) \n",
    "\n",
    "plt.plot(t, np.abs(dAdk1))\n",
    "plt.plot(t, np.abs(dAdk_1))\n",
    "plt.xlim([0, 0.5])\n",
    "plt.ylim([0, 0.1])\n",
    "plt.xlabel(\"t\")\n",
    "plt.legend([\"$S_{k1}$\", \"$S_{k\\_1}$\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uVlzjHuUtHP"
   },
   "source": [
    "That looks like the figure in the paper. To summarize the main takeaway, jax enabled us to readily compute derivatives without having to derive them manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yhTXLEdrUtHQ"
   },
   "source": [
    "# Summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgueVg4EUtHQ"
   },
   "source": [
    "These are just some of *many* possible applications of automatic differentiation in mathematics and engineering. The key points you should take away from this is that it is often possible to program with derivatives, and to compute derivatives automatically in many cases. This enables you to think about writing programs that reflect the mathematical and scientific ideas you are trying to implement more directly, and in many cases less approximately.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterquiz import display_quiz\n",
    "display_quiz('.quiz.json')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "20-autograd-applications.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "org": {
   "KEYWORDS": "autograd"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
